{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_summariser_attention.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhaveshsingh0206/Text-Summmariser./blob/master/text_summariser_attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sFS4bBo7eV_",
        "colab_type": "code",
        "outputId": "f34fdfb8-b155-4838-e97a-f17c8346e908",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Embedding, LSTM, Bidirectional, RepeatVector, Concatenate, Dot, Lambda\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import Input, Model\n",
        "import keras.backend as K"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuHmslRA7kqu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading file from Drive\n",
        "import pydrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkslQKUm7ngV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34ndCyf07oxf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "downloaded = drive.CreateFile({'id':\"1FfO8fsNXnenTfsq7skCgZpv6PBBQhjpa\"})   \n",
        "downloaded.GetContentFile('glove.6B.100d.txt')  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UU7W0nmk7vap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "downloaded = drive.CreateFile({'id':\"13JdWTJ4hSKpUQnOlAxmzTdjNVUjco4fV\"}) \n",
        "downloaded.GetContentFile('DF.csv') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMQslS2L7xQV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word2Vec = {}\n",
        "with open('glove.6B.100d.txt') as f:\n",
        "  for line in f:\n",
        "    line = line.rstrip().split(' ')\n",
        "    word = line[0]\n",
        "    embedding_vector = line[1:]\n",
        "    word2Vec[word] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRVAX0Ot7zcq",
        "colab_type": "code",
        "outputId": "1bd3530e-a3bd-4f46-8070-4b0f7e0a29cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "dataset = pd.read_csv('DF.csv')\n",
        "dataset.head()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headlines</th>\n",
              "      <th>article</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>India reports more than 5,000 coronavirus case...</td>\n",
              "      <td>The total number of coronavirus cases in India...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Because of few jokers, COVID-19 is spreading: ...</td>\n",
              "      <td>Salman Khan has condemned the attack on medica...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>45% districts without a COVID-19 case, 27 dist...</td>\n",
              "      <td>The government on Thursday announced that 45% ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>68-yr-old UP man suffering from cold declared ...</td>\n",
              "      <td>A 68-year-old man from Uttar Pradesh's Amroha,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Lockdown is like pause button, will not defeat...</td>\n",
              "      <td>Addressing the media via video on Thursday, Co...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           headlines                                            article\n",
              "0  India reports more than 5,000 coronavirus case...  The total number of coronavirus cases in India...\n",
              "1  Because of few jokers, COVID-19 is spreading: ...  Salman Khan has condemned the attack on medica...\n",
              "2  45% districts without a COVID-19 case, 27 dist...  The government on Thursday announced that 45% ...\n",
              "3  68-yr-old UP man suffering from cold declared ...  A 68-year-old man from Uttar Pradesh's Amroha,...\n",
              "4  Lockdown is like pause button, will not defeat...  Addressing the media via video on Thursday, Co..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwSWPGt073As",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LEN = 100\n",
        "MAX_VOCAB = 30000\n",
        "LSTM_UNITS = 256\n",
        "DIMENSIONS = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48X6i9jh747U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "input_sequences = []\n",
        "target_input_sequences = []\n",
        "target_sequences = []\n",
        "for index, row in dataset.iterrows():\n",
        "  input_sequences.append(row['article'])\n",
        "  target_input_sequences.append('<sos> '+row['headlines'])\n",
        "  target_sequences.append(row['headlines']+' <eos>')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ceg_y64IJvz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(input_sequences[0])\n",
        "print(target_input_sequences[0])\n",
        "print(target_sequences[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTlt9ogY76b4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_input_len = max(len(s.split(' ')) for s in input_sequences)\n",
        "max_target_len = max(len(y.split(' ')) for y in target_sequences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0GZHG4r78IV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"target length max is \",max_target_len, \" input length max is \",max_input_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHvpYQ337_Cg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer_input = Tokenizer(num_words=MAX_VOCAB)\n",
        "tokenizer_input.fit_on_texts(input_sequences)\n",
        "input_sequences = tokenizer_input.texts_to_sequences(input_sequences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dt_2cU3p8Ar7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer_output = Tokenizer(num_words=MAX_VOCAB)\n",
        "tokenizer_output.fit_on_texts(target_input_sequences+target_sequences)\n",
        "target_input_sequences = tokenizer_output.texts_to_sequences(target_input_sequences)\n",
        "target_sequences = tokenizer_output.texts_to_sequences(target_sequences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBkKfnUO8B_5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words_input = tokenizer_input.word_index\n",
        "words_output = tokenizer_output.word_index\n",
        "input_num_words = min(MAX_VOCAB, len(words_input)+1)\n",
        "target_num_words = min(MAX_VOCAB, len(words_output)+1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KMqeqfb8DRD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_sequences = pad_sequences(input_sequences, max_input_len, padding='pre')\n",
        "target_input_sequences = pad_sequences(target_input_sequences, max_target_len, padding='post')\n",
        "target_sequences = pad_sequences(target_sequences, max_target_len, padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8E83Oye48Ekn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_embedding_matrix = np.zeros((input_num_words, DIMENSIONS))\n",
        "for word, k in words_input.items():\n",
        "  if k < input_num_words:\n",
        "    embedding_vector = word2Vec.get(word)\n",
        "    if embedding_vector is not None:\n",
        "      input_embedding_matrix[k] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdAFzqvy8Fz6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_embedding_matrix = np.zeros((target_num_words, DIMENSIONS))\n",
        "for word, k in words_input.items():\n",
        "  if k < target_num_words:\n",
        "    embedding_vector = word2Vec.get(word)\n",
        "    if embedding_vector is not None:\n",
        "      target_embedding_matrix[k] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcT8OCYk8HOb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_input = Input(shape=(max_input_len,))\n",
        "embedding_input_layer = Embedding(input_num_words, DIMENSIONS, weights=[input_embedding_matrix], trainable=True)\n",
        "x = embedding_input_layer(embedding_input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAyoD24v8n2-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_lstm1 = Bidirectional(LSTM(LSTM_UNITS, return_sequences=True))\n",
        "input_lstm1_output = input_lstm1(x)\n",
        "\n",
        "input_lstm2 = Bidirectional(LSTM(LSTM_UNITS, return_sequences=True))\n",
        "encoder_output = input_lstm2(input_lstm1_output)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_oSnzu19aqp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def softmax_over_time(x):\n",
        "  assert(K.ndim(x) > 2)\n",
        "  e = K.exp(x - K.max(x, axis=1, keepdims=True))\n",
        "  s = K.sum(e, axis=1, keepdims=True)\n",
        "  return e / s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8qvzhYp9HTk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "atten_layer_repeat = RepeatVector(max_input_len)\n",
        "atten_concatenate = Concatenate(axis=-1)\n",
        "atten_dense1 = Dense(30, activation='tanh')\n",
        "atten_dense2 = Dense(1, activation=softmax_over_time)\n",
        "attn_dot = Dot(axes=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HwA2OmL92QA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def attention_procedure(h, st_1):\n",
        "  st_1 = atten_layer_repeat(st_1)\n",
        "  x = atten_concatenate([h, st_1])\n",
        "  x = atten_dense1(x)\n",
        "  alphas = atten_dense2(x)\n",
        "  context = attn_dot([alphas,h])\n",
        "  return context"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lb2hgdsUByRi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "st_0 = Input(shape=(LSTM_UNITS,))\n",
        "c_0 = Input(shape=(LSTM_UNITS,))\n",
        "context_last_word_concat_layer = Concatenate(axis=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9alUz7G3-nQ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_decoder_input = Input(shape=(max_target_len,))\n",
        "embedding_decoder_layer = Embedding(target_num_words, DIMENSIONS, weights=[target_embedding_matrix], trainable=True)\n",
        "decoder_x = embedding_decoder_layer(embedding_decoder_input)\n",
        "\n",
        "s = st_0\n",
        "c = c_0\n",
        "outputs = []\n",
        "decoder_lstm = LSTM(LSTM_UNITS, return_state=True)\n",
        "decoder_dense_layer = Dense(target_num_words, activation='softmax')\n",
        "for i in range(max_target_len):\n",
        "  context = attention_procedure(encoder_output, s)\n",
        "\n",
        "  selector = Lambda(lambda x: x[:, i:i+1])\n",
        "  xt = selector(decoder_x)\n",
        "  decoder_lstm_input = context_last_word_concat_layer([context, xt])\n",
        "  \n",
        "  \n",
        "  decoder_lstm_output, s, c = decoder_lstm(decoder_lstm_input, initial_state=[s,c])\n",
        "\n",
        "  \n",
        "  decoder_output = decoder_dense_layer(decoder_lstm_output)\n",
        "  outputs.append(decoder_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cn8iPDjAC60j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def stack_and_transpose(x):\n",
        "  x = K.stack(x) \n",
        "  x = K.permute_dimensions(x, pattern=(1, 0, 2)) \n",
        "  return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfjYFhypHN20",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stacker = Lambda(stack_and_transpose)\n",
        "outputs = stacker(outputs)\n",
        "\n",
        "model = Model(\n",
        "  inputs=[\n",
        "    embedding_input,\n",
        "    embedding_decoder_input,\n",
        "    st_0, \n",
        "    c_0,\n",
        "  ],\n",
        "  outputs=outputs\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMlJFWGhHYIg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SPFeuU9JeQu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# my_callbacks = [\n",
        "#     ModelCheckpoint(filepath = 'my_model.h5', \n",
        "#     verbose=1, save_best_only=True, save_weights_only=False) \n",
        "#     ]\n",
        "model.load_weights('/content/gdrive/My Drive/model/epochs:011-val_acc(part2):0.687.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ri5QNVB_6O5H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import *\n",
        "filepath=\"/content/gdrive/My Drive/model/epochs:{epoch:03d}-val_acc(part2):{val_acc:.3f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97uyPTvzHdTP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
        "\n",
        "z = np.zeros((len(target_sequences), LSTM_UNITS))\n",
        "r = model.fit(\n",
        "  [input_sequences, target_input_sequences, z, z], target_sequences.reshape(target_sequences.shape[0],target_sequences.shape[1], 1),\n",
        "  batch_size=128,\n",
        "  epochs=20,\n",
        "  validation_split=0.2,\n",
        "  verbose=1,\n",
        "  callbacks=callbacks_list\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUWuyAkHIRdt",
        "colab_type": "code",
        "outputId": "368678e7-bb7c-435e-fba4-4043d8bb9dec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yl1Ao3cIJGlx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Epoch 00007: val_acc improved from 0.65365 to 0.65503, saving model to /content/gdrive/My Drive/model/epochs:007-val_acc:0.655.hdf5\n",
        "Epoch 8/40\n",
        "51275/51275 [==============================] - 3589s 70ms/step - loss: 2.6328 - acc: 0.6448 - val_loss: 2.9198 - val_acc: 0.6557\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvLzMh9lJLzk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predictions!!!!!!!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuWN2adOvTtN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rC9vexmm1jAm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfoPOc391p0s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZXg06t61r1_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_outputs_as_input = Input(shape=(max_input_len, LSTM_UNITS * 2,))\n",
        "decoder_inputs_single = Input(shape=(1,))\n",
        "decoder_inputs_single_x = embedding_decoder_layer(decoder_inputs_single)\n",
        "\n",
        "context = attention_procedure(encoder_outputs_as_input, st_0)\n",
        "\n",
        "\n",
        "decoder_lstm_input = context_last_word_concat_layer([context, decoder_inputs_single_x])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "o, s, c = decoder_lstm(decoder_lstm_input, initial_state=[st_0, c_0])\n",
        "decoder_outputs = decoder_dense_layer(o)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "decoder_model = Model(\n",
        "  inputs=[\n",
        "    decoder_inputs_single,\n",
        "    encoder_outputs_as_input,\n",
        "    st_0, \n",
        "    c_0\n",
        "  ],\n",
        "  outputs=[decoder_outputs, s, c]\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytozipPI1uQE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_model = Model(embedding_input, encoder_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdNDiLto4WAf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idx2word = {v:k for k, v in words_output.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QuRWJpZ3UiH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prediction(input_seq):\n",
        "\n",
        "  enc_out = encoder_model.predict([[input_seq]])\n",
        "\n",
        "  target_seq = np.zeros((1, 1))\n",
        "  \n",
        "\n",
        "  target_seq[0, 0] = words_output['sos']\n",
        "\n",
        "  eos = words_output['eos']\n",
        "\n",
        "\n",
        "\n",
        "  s = np.zeros((1, LSTM_UNITS))\n",
        "  c = np.zeros((1, LSTM_UNITS))\n",
        "\n",
        "\n",
        "  output_sentence = []\n",
        "  for _ in range(max_target_len):\n",
        "    o, s, c = decoder_model.predict([target_seq, enc_out, s, c])\n",
        "        \n",
        "\n",
        "    idx = np.argmax(o.flatten())\n",
        "\n",
        "    if eos == idx:\n",
        "      break\n",
        "\n",
        "    word = ''\n",
        "    if idx > 0:\n",
        "      word = idx2word[idx]\n",
        "      output_sentence.append(word)\n",
        "\n",
        "\n",
        "    target_seq[0, 0] = idx\n",
        "\n",
        "  return ' '.join(output_sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvjTk3wRk22l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "predictions_inputs = []\n",
        "true_outputs = []\n",
        "count = 0\n",
        "while count<5:\n",
        "  id = random.randint(0,100)\n",
        "  predictions_inputs.append(dataset['article'][id])\n",
        "  true_outputs.append(dataset['headlines'][id])\n",
        "  count += 1\n",
        "predictions_inputs = tokenizer_input.texts_to_sequences(predictions_inputs)\n",
        "predictions_inputs = pad_sequences(predictions_inputs, maxlen=max_input_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfhr2iay4qwX",
        "colab_type": "code",
        "outputId": "6815ef05-4447-4bb5-c272-7a24f622e4e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "for k,text in enumerate(predictions_inputs):\n",
        "  print(len(text))\n",
        "  print('ARTICLE IS')\n",
        "  print('---------------------')\n",
        "  print('ORIGINAL HEADLINE IS')\n",
        "  print(true_outputs[k])\n",
        "  print('---------------------')\n",
        "  print('PREDICTED HEADLINE IS')\n",
        "  print(prediction(text))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "87\n",
            "ARTICLE IS\n",
            "---------------------\n",
            "ORIGINAL HEADLINE IS\n",
            "Odisha's Ganjam imposes ₹500 fine for spitting in public places\n",
            "---------------------\n",
            "PREDICTED HEADLINE IS\n",
            "himachal pradesh bans coronavirus fear in public ban public\n",
            "87\n",
            "ARTICLE IS\n",
            "---------------------\n",
            "ORIGINAL HEADLINE IS\n",
            "Uttar Pradesh reports 67 new coronavirus cases, state total rises to 727\n",
            "---------------------\n",
            "PREDICTED HEADLINE IS\n",
            "coronavirus cases in new york state total reaches 9 to cases today\n",
            "87\n",
            "ARTICLE IS\n",
            "---------------------\n",
            "ORIGINAL HEADLINE IS\n",
            "Consulted 12-13 doctors in family: Kumaraswamy defends son's wedding tomorrow\n",
            "---------------------\n",
            "PREDICTED HEADLINE IS\n",
            "10 yr old my family even even even day night or vote on coronavirus lockdown\n",
            "87\n",
            "ARTICLE IS\n",
            "---------------------\n",
            "ORIGINAL HEADLINE IS\n",
            "UK thanks India as country gets 1st batch of 28 lakh paracetamol packs\n",
            "---------------------\n",
            "PREDICTED HEADLINE IS\n",
            "uk thanks india as country gets 1st 28 lakh lakh united of 14 years\n",
            "87\n",
            "ARTICLE IS\n",
            "---------------------\n",
            "ORIGINAL HEADLINE IS\n",
            "I disagree with PM a lot but today we need to fight COVID-19 together: Rahul\n",
            "---------------------\n",
            "PREDICTED HEADLINE IS\n",
            "we will fight pm modi with me but we fight against covid 19 rahul gandhi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aO2XjML47_u",
        "colab_type": "code",
        "outputId": "587cd97e-3fbb-4959-f6e5-877f1edf77a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(predictions_inputs[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "87"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "270zJ4pM5hIk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}